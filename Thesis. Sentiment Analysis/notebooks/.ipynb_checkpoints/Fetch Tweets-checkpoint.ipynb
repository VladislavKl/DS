{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Tweets\n",
    "\n",
    "Donwload and save tweets, using a **query** value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = Path('../.env').resolve()\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API access\n",
    "\n",
    "First of all, we'll connect to the Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "consumer_key = os.getenv(\"CONSUMER_KEY\")\n",
    "consumer_secret = os.getenv(\"CONSUMER_SECRET\")\n",
    "access_token = os.getenv(\"ACCESS_TOKEN\")\n",
    "access_token_secret = os.getenv(\"ACCESS_TOKEN_SECRET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tweepy import OAuthHandler, API, TweepError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to the Twitter API.\n"
     ]
    }
   ],
   "source": [
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Tweets\n",
    "\n",
    "Now we can define our query and search for the tweets containing it.\n",
    "\n",
    "- **query**: *hashtag* or *emoji* that will be used to fetch the tweets\n",
    "- **max_requests**: Maximum number of requests to the API.\n",
    "    - Restriction: 180 requests / 15 min window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'message': 'Rate limit exceeded', 'code': 88}]\n",
      ":face_screaming_in_fear:\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from emoji import emojize\n",
    "\n",
    "relations_path = Path('../query_relations.json')\n",
    "with relations_path.open('r') as file:\n",
    "    relations = json.load(file)\n",
    "queries = [key for key, value in relations.items()]\n",
    "for symbol in queries:\n",
    "    query = symbol\n",
    "    max_requests = 90\n",
    "    # Converts aliases to the real emoji representation (e.g. :thumbs_up: => 👍)\n",
    "\n",
    "    \n",
    "    q = emojize(query) + ' -filter:retweets'\n",
    "    searched_tweets = []\n",
    "    last_id = -1\n",
    "    request_count = 0\n",
    "    while request_count < max_requests:\n",
    "        try:\n",
    "            new_tweets = api.search(q=q,\n",
    "                                    lang='en',\n",
    "                                    count=100,\n",
    "                                    max_id=str(last_id - 1),\n",
    "                                    tweet_mode='extended')\n",
    "            if not new_tweets:\n",
    "                break\n",
    "            searched_tweets.extend(new_tweets)\n",
    "            last_id = new_tweets[-1].id\n",
    "            request_count += 1\n",
    "        except TweepError as e:\n",
    "            print(e)\n",
    "            break\n",
    "    data = []\n",
    "    for tweet in searched_tweets:\n",
    "        data.append([tweet.id, tweet.created_at, tweet.user.screen_name, tweet.full_text])\n",
    "    df = pd.DataFrame(data=data, columns=['id', 'date', 'user', 'text'])\n",
    "    PATH = Path('../datasets/tweepy').resolve()\n",
    "    filename = query + '.csv'\n",
    "    df.to_csv(os.path.join(PATH, filename), index=None)\n",
    "    print(query)\n",
    "    time.sleep(60*5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
